{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "from sklearn.ensemble import RandomForestRegressor as RF\n",
    "from sklearn.tree import DecisionTreeRegressor as DTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_y = pd.read_csv('train_y.csv', header=None, usecols=(1,1))\n",
    "train_x = pd.read_csv('train_x.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Segmenting continuous and categorical columns\n",
    "cat_list = pd.read_csv('train_cat_list.csv')\n",
    "cat_list = list(cat_list['0'])\n",
    "cnt_list = [x for x in train_x.columns if x not in cat_list]\n",
    "cont_col = np.concatenate([cnt_list, cat_list])  # All columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Shortlisting the features properly, by making further segments depending upon the VIF values\n",
    "# Putting a cut off for vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#VIF function - returns VIF dataset for specified columns\n",
    "def vif_calc(data, col_roll, cutoff = 7.5):\n",
    "    print 'Calculating VIF...'\n",
    "    vif_col = pd.DataFrame()\n",
    "    for col in range(data[col_roll].shape[1]):\n",
    "        vif_col = vif_col.append({'var': data[col_roll].columns[col],\n",
    "                                  'VIF' : vif(data[col_roll].as_matrix(), col)}, ignore_index = True)\n",
    "    \n",
    "    vif_col['VIF_type'] = np.where(vif_col['VIF'] >= cutoff, 'High', 'Low')\n",
    "    print 'VIF check completed.'\n",
    "    print 'Dataframe with VIF values', vif_col.shape\n",
    "    return vif_col\n",
    "\n",
    "\n",
    "# RF wrapper - returns variable importance \n",
    "def RF_wrap(data, target, col_names, imp_cutoff = 0.005, n_trees = 500, verbose = False, oob_score = False, min_samples_leaf = 5):\n",
    "    max_features = int(round(0.4*col_names.shape[0]))\n",
    "    rf =  RF(n_estimators = n_trees, oob_score = oob_score, random_state = 1203, max_features = max_features, \n",
    "             min_samples_leaf = min_samples_leaf, verbose = verbose)\n",
    "    print 'Fitting RF regressor..'\n",
    "    rf.fit(data[col_names], target)\n",
    "    print 'Getting Variable Importance..'\n",
    "    imp = pd.concat([pd.DataFrame(data[col_names].columns), pd.DataFrame(rf.feature_importances_)], axis=1)\n",
    "    imp.columns = ['Variable', 'Importance']\n",
    "    imp['Imp_type'] = np.where(imp['Importance'] >= imp_cutoff, 'High', 'Low')\n",
    "    print 'Done'\n",
    "    print 'Dataframe with RF feature selection', imp.shape\n",
    "    return imp\n",
    "\n",
    "\n",
    "# DecisionTree wrapper - returns variable importance \n",
    "def Tree_wrap(data, target, col_names, imp_cutoff = 0.005, min_samples_leaf = 5, min_samples_split = 10):\n",
    "    max_features = int(round(0.4*col_names.shape[0]))\n",
    "    dtr =  DTR(random_state = 1203, max_features = max_features,\n",
    "               min_samples_leaf =min_samples_leaf, min_samples_split =min_samples_split)\n",
    "    print 'Fitting Decision Tree regressor..'\n",
    "    dtr.fit(data[col_names], target)\n",
    "    print 'Getting Variable Importance..'\n",
    "    imp = pd.concat([pd.DataFrame(data[col_names].columns), pd.DataFrame(dtr.feature_importances_)], axis=1)\n",
    "    imp.columns = ['Variable', 'Importance']\n",
    "    imp['Imp_type'] = np.where(imp['Importance'] >= imp_cutoff, 'High', 'Low')\n",
    "    print 'Done'\n",
    "    print 'Dataframe with Decision Tree feature selection', imp.shape\n",
    "    return imp\n",
    "\n",
    "\n",
    "#  Wrapper for selecting continuous features - returns ANOVA F-value\n",
    "def f_wrap(data, target, col_names, p_cutoff = 0.05):\n",
    "    fdat = f_classif(data[col_names], target)[1]\n",
    "    fdat_df = pd.concat([pd.DataFrame(data[col_names].columns), pd.DataFrame(fdat)], axis=1)\n",
    "    fdat_df.columns = ['Variable', 'P_value_fclass']\n",
    "    fdat_df['Imp_type'] = np.where(fdat_df['P_value_fclass'] > p_cutoff, 'Low', 'High')\n",
    "    print 'Dataframe with Anova-F feature selection', fdat_df.shape\n",
    "    return fdat_df\n",
    "\n",
    "\n",
    "#  Wrapper for selecting categorical features - returns Chi2 P-value\n",
    "def chi2_wrap(data, target, col_names, p_cutoff = 0.05):\n",
    "    chdat = chi2(data[col_names], target)[1]\n",
    "    chdat_df = pd.concat([pd.DataFrame(data[col_names].columns), pd.DataFrame(chdat)], axis=1)\n",
    "    chdat_df.columns = ['Variable', 'P_value_chi2']\n",
    "    chdat_df['Imp_type'] = np.where(chdat_df['P_value_chi2'] > p_cutoff, 'Low', 'High')    \n",
    "    print 'Dataframe with Chi2 feature selection', chdat_df.shape\n",
    "    return chdat_df\n",
    "\n",
    "\n",
    "#  Wrapper for calling feature selection methods \n",
    "#  method parameter takes the values 'rf', 'tree', 'anovaf', 'chi2'\n",
    "def method_call(data, target, cols, method, pcut = 0.05, impcut = 0):\n",
    "    if method == 'rf':\n",
    "        method_df = RF_wrap(data, target, np.asarray(cols), imp_cutoff = impcut)\n",
    "        method_df['Measure'] = \"Importance\"\n",
    "        print 'Done'\n",
    "        \n",
    "    elif method == 'tree':\n",
    "        method_df = Tree_wrap(data, target, np.asarray(cols), imp_cutoff = impcut)\n",
    "        method_df['Measure'] = \"Importance\"\n",
    "        print 'Done'\n",
    "    \n",
    "    elif method == 'anovaf':\n",
    "        method_df = f_wrap(data, target, cols, p_cutoff = pcut)\n",
    "        method_df.columns = ['Variable', 'Importance', 'Imp_type']\n",
    "        method_df['Measure'] = \"P-value\"\n",
    "        print 'Done'\n",
    "        \n",
    "    else:\n",
    "        method_df = chi2_wrap(data, target, cols, p_cutoff = pcut)\n",
    "        method_df.columns = ['Variable', 'Importance', 'Imp_type']\n",
    "        method_df['Measure'] = \"P-value\"\n",
    "        print 'Done'\n",
    "    \n",
    "    return method_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Feature selection wrapper; returns a dataframe with variable name, variable type, respective P-value/Importances, etc.\n",
    "\n",
    "#categ_method argument takes 'rf', 'tree', 'chi2'\n",
    "#cont_method argument takes 'rf', 'tree', 'anovaf'\n",
    "\n",
    "def allvarsel2(data, target, itername, cont_col = cont_col, cont_method ='rf', categ_method ='rf', VIF_cutoff = 5, \n",
    "               imp_cutoff = 0, p_cutoff = 0.05, cont_list = cnt_list, categ_list = cat_list):\n",
    "    \n",
    "    ##Calculate VIF for continuous variables\n",
    "    check = vif_calc(data, col_roll=cont_col, cutoff = VIF_cutoff)\n",
    "    check.to_csv('/home/pgoyal/Projects/app/' + str(itername) + '.csv', index = False)\n",
    "    lowvif = check.copy()\n",
    "    highvif = check[check.VIF_type.values == 'High']['var'].as_matrix()\n",
    "    lowvif = check[check.VIF_type.values == 'Low']['var'].as_matrix()\n",
    "    \n",
    "    #Feature selection for continuous variables with high VIF\n",
    "    print 'Fitting ', cont_method, ' on variables with High VIF...'\n",
    "    high_vif_df = method_call(data, target, cols = highvif, method = cont_method, pcut = p_cutoff, impcut =imp_cutoff)\n",
    "    high_vif_df['Var_data'] = \"High VIF - all datasets\"    \n",
    "    highvif_imp = high_vif_df[high_vif_df.Imp_type.values == 'High']['Variable'].as_matrix()\n",
    "    \n",
    "    #Segregate variables with low VIF according to datasource  \n",
    "    hist_rf_var = [val for val in lowvif if val in cont_list]\n",
    "     \n",
    "    #Feature selection for low VIF variables from latest transaction (historical) data\n",
    "    print 'Fitting ', cont_method, ' on Historical - latest variables...'\n",
    "    hist_rf_df = method_call(data, target, cols = hist_rf_var, method = cont_method, pcut = p_cutoff, impcut =imp_cutoff)\n",
    "    hist_rf_df['Var_data'] = \"Historical - latest\"\n",
    "\n",
    "    #Convert shorlisted variables into matrix form\n",
    "    hist_rf_imp = hist_rf_df[hist_rf_df.Imp_type.values == 'High']['Variable'].as_matrix()\n",
    "    \n",
    "    #Feature selection for categorical variables from transaction(historical) data\n",
    "    print 'Fitting ', categ_method, ' on Categorical variables...'\n",
    "    categ_var = method_call(data, target, cols = categ_list, method = categ_method, pcut = p_cutoff, impcut =imp_cutoff)\n",
    "    categ_var['Var_data'] = \"Categorical\"\n",
    "    categ_var_imp = categ_var[categ_var.Imp_type.values == 'High']['Variable'].as_matrix()\n",
    "    \n",
    "    #Append shortlisted variables/importance dataframes to create a common list/dataframe\n",
    "    selvar = np.concatenate([highvif_imp, hist_rf_imp, categ_var_imp])\n",
    "    vardf = pd.concat([high_vif_df, hist_rf_df, categ_var], axis=0)\n",
    "    \n",
    "    return vardf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating VIF...\n",
      "VIF check completed.\n",
      "Dataframe with VIF values (272, 3)\n",
      "Fitting  rf  on variables with High VIF...\n",
      "Fitting RF regressor..\n",
      "Getting Variable Importance..\n",
      "Done\n",
      "Dataframe with RF feature selection (22, 3)\n",
      "Done\n",
      "Fitting  rf  on Historical - latest variables...\n",
      "Fitting RF regressor..\n",
      "Getting Variable Importance..\n",
      "Done\n",
      "Dataframe with RF feature selection (250, 3)\n",
      "Done\n",
      "Fitting  rf  on Categorical variables...\n",
      "Fitting RF regressor..\n",
      "Getting Variable Importance..\n",
      "Done\n",
      "Dataframe with RF feature selection (22, 3)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Using the function\n",
    "\n",
    "featsel1 = allvarsel2(train_x, np.ravel(train_y[1]), itername = 'train_data', cont_method = 'rf', categ_method = 'rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shortlisting the continuous features by cross checking the list of VIFs : 107 have been shortlisted ; \n",
    "# check train_data_xls.xls file for the shortlisted variables marked in Yellow color\n",
    "cnts_vars_final = pd.DataFrame(cnt_list)\n",
    "cnts_vars_final.to_csv('cnt_vars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selecting the top variables 107 variables from the list of variables on the basis of VIF\n",
    "# cnts_vars_final = ['f_158','f_19','f_154','f_48','f_202','f_113','f_69','f_27','f_74','f_240','f_6','f_108','f_118',\n",
    "#                   'f_112','f_227','f_177','f_110','f_53','f_4','f_231','f_246','f_152','f_201','f_0','f_225','f_184',\n",
    "#                   'f_56','f_16','f_90','f_37','f_200','f_203','f_129','f_236','f_46','f_182','f_100','f_176','f_251',\n",
    "#                   'f_247','f_17','f_206','f_238','f_23','f_24','f_126','f_127','f_64','f_41','f_111','f_65','f_22',\n",
    "#                   'f_128','f_136','f_107','f_92','f_122','f_78','f_2','f_10','f_59','f_229','f_125','f_33','f_40',\n",
    "#                   'f_170','f_159','f_5','f_174','f_194','f_241','f_77','f_199','f_140','f_198','f_178','f_216',\n",
    "#                   'f_188','f_120','f_131','f_144','f_67','f_50','f_221','f_60','f_42','f_180','f_76','f_226',\n",
    "#                   'f_149','f_1','f_73','f_18','f_155','f_173','f_85','f_135','f_248','f_68','f_191','f_252',\n",
    "#                   'f_98','f_204','f_45','f_58','f_28','f_183']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using all categorical variables as of now\n",
    "pd.DataFrame(cat_list).to_csv('cat_vars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
